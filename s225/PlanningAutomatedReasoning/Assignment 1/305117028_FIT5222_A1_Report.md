
***"The question of whether Machines Can Think... is about as relevant as the question of whether Submarines Can Swim."***  
~ Edsger Dijkstra  
***"The art of progress is to preserve order amid change and to preserve change amid order."***  
~ Alfred North Whitehead 
## Introduction

It is important to consider the value of *practical solutions* a pathing algorithm can provide at the cost of a sometimes coveted desideratum for algorithms:  *optimality*.  Multi-Agent Path Finding (MAPF) is a central problem in artificial intelligence and robotics that involves finding collision-free paths for multiple agents in a shared (often dynamic) environment. The challenge is especially relevant in railway systems, by which this project addresses. The agents (trains) are constrained by physical tracks. They cannot move arbitrarily across a grid; and their trajectories must follow predetermined rail transitions. Moreover, trains face additional stochastic elements: malfunctions such as mechanical failures or unplanned stops. 

This report presents decisions, and evaluations of a multi-agent railway path planning system built on Safe Interval Path Planning (SIPP) and reservation tables for conflict avoidance. The system was developed iteratively, beginning with simple A* search, then evolving through CBS-like strategies, before finally settling on SIPP to handle both temporal and spatial collisions.

The first part of the report demonstrates theoretical understanding by drawing reasonable connections between the differing implemented algorithms starting from Breadth-First-Search (BFS) to MAPF with Reservation Tables. The second part describes the development journey, including the challenges encountered and the debugging strategies applied. The third part provides a critical reflection on my implementation and experiments. 

The broader significance of this work lies in looking at the MAPF algorithm as a sub-optimal computable system, abstracted away from the in-numerous particulars of real-time dynamic environments in the real world.

---

## Background and Theoretical Foundations

### Multi-Agent Path Finding (MAPF)

According to Fioravantes et. al, "The Mutliagent Path Finding (MAPF) problem consists of identifying the trajectories that a set of agents should follow inside a given network in order to reach their desired destinations as soon as possible, but without colliding with each other." (Fioravantes, 2025) In our case, time is discretized into timesteps and the environment into grid cells, and traversed as graph nodes. Agents may move from one cell to an adjacent one, or wait in place, subject to constraints. As one can guess, the complexity comes from the rail tracks and fellow agents. Following the standard graph-theoretic notation, Let ğº = (ğ‘‰ , ğ¸) be a graph. For a subset of vertices ğ‘ˆ âŠ† ğ‘‰ and a vertex ğ‘¢ âˆˆ ğ‘‰ we denote by ğ‘ğ‘ˆ (ğ‘¢) the neighborhood of $ğ‘¢ \in ğ‘ˆ$ , that is, the set of vertices of ğ‘ˆ that are adjacent to ğ‘¢. By $ğ‘ğ‘ˆ_u$ we mean ğ‘ğ‘ˆ (ğ‘¢) âˆª {ğ‘¢}. We say that a schedule $s1, . . . , s_m$ is a feasible solution of an instance,
$$\begin{matrix}I = âŸ¨ğº, ğ´, ğ‘ 0, ğ‘¡, â„“âŸ© \ of \ MAPF \ \ if:  \\
(1) \ ğ‘ _i(ğ‘) âˆˆ ğ‘ [ğ‘ ğ‘–âˆ’1 (ğ‘)] \ \forall ğ‘ âˆˆ ğ´ \ \& \ \forall ğ‘– âˆˆ [ğ‘š],  \\
(2) \ ğ‘ _i(ğ‘) â‰  ğ‘ _i(ğ‘): \forall a (ğ‘– âˆˆ [ğ‘š] \ \& \ ğ‘ â‰  ğ‘ âˆˆ ğ´), \\
(3) \ ğ‘ _ğ‘š = ğ‘¡.\end{matrix}$$

MAPF is an NP-hard scheduling problem which has motivated a wide range of algorithmic approaches attempting to balance optimality, scalability, and runtime efficiency.

Performance is often measured using objectives such as **makespan** (the time until the last agent reaches its goal) and **sum of costs** (the sum of travel times of all agents),
$$\sum_{i \in A}|\pi_i|$$
where plansÂ $(Ï€_i,iâˆˆA)$  are single-agent plans without collisions. We can then derive makespan: $$\underset{i \in A}{max}|\pi_i| \implies i\in A \ as \ valid$$
One possible approach to face the computational complexity is *prioritized planning*. It consists in decoupling the MAPF problem intoÂ $K$ Â problems. The first step is to assign to each agent a unique numberÂ {1,2,...,k} that corresponds to the priority given to the agent. Then, following the priority order, for each agent a plan is computed to reach the target location.

The drawback of prioritized planning is that, even if it returns valid solutions, it is neither optimal nor complete, i.e., it is not assured that the algorithm will return a solution and, even in that case, the solution may over-estimate the solution cost and be non-monotonic.

The problem is also compounded by domain-specific sub-problems. In the railway environment of the Flatland simulator, agents are restricted to valid rail transitions. It is easy to image a combinatorial explosion as a result of even adding one of the deceptively smallest real-world attributes. (Geft, 2023 & Nebel, 2023)

### BFS, A* and Heuristic Search in MAPF

A single-agent-shortest-path approach can be solved efficiently using either **Breadth-First Search (BFS)**, where the search is expanded "horizontally" where all adjacent parent nodes are expanded first or **A-Star (A*)*** search, which under non-dynamic conditions, always provides an optimal solution (as it is both admissible and consistent, such that it never overestimates the cost of reach the target). A* is guided by the output of the function taken as the sum of the actual cost of the goal node and the estimated cost of the successor node for each step. 
$$A^*(x_i)= h(x_i)+g(x_i)$$
When applied to graph-based domains, BFS is optimal in unweighted domains fails in scaling well when the branching factor is large. A* instead is guided by its heuristic function to guide the search toward the goal more efficiently.

In MAPF, one naÃ¯ve approach is to plan paths for each agent independently using A* or BFS. However, this often leads to collisions, since agents ignore each otherâ€™s presence. But in multi-agent contexts, planning independently with A* is insufficient.

### Conflict-Based Search (CBS)

To address conflicts explicitly, one approach is to employ a **Conflict-Based Search (CBS)**. CBS is a two-level algorithm. At the low level, each agentâ€™s path is planned independently using A*. At the high level, conflicts between agents are detected and resolved by introducing a *permission* constraint. We have, 

$N$ - contains a plan of minimum cost with constraints
$T$ - time constraint
$minf$ - total min cost
$C$ - cost

CBS is complete and optimal but suffers from exponential instabilitiy. If for each valid solution $S$, there exists a node with constraints $N_{c_i...c_n}$ , then we can say that the minimum cost for any solution is:
$$S_{minf} = C \le N_{c_i...c_n} $$
But this is trivially optimal since we are not taking into consideration the dynamical nature of the problem. Any increase the cardinality of the permission constraint set would result in the solution space to be$$s \in S= \prod_{a_i \in A}|P_{a_i}|$$
where $P_{a_i}$ is the set of all possible paths for agent $a_i$.

Nevertheless, CBS provides an elegant way of decomposing the MAPF problem into single-agent planning plus incremental constraint resolution.

### Safe Interval Path Planning (SIPP)

**Safe Interval Path Planning (SIPP)**, introduced by Phillips and Likhachev (SOURCE: Phillips, Lichachev, 2011), is a variant of A* that operates in continuous time. Instead of associating each node with a single position, SIPP associates it with a safe interval, that is, a *range* of times during which the position is free of conflicts.

When expanding nodes, SIPP computes feasible moves by checking the agentâ€™s arrival time against safe intervals, ensuring that agents never enter a cell at a time when it is occupied. This makes SIPP particularly effective for environments with dynamic obstacles or temporal constraints. In my implementation, SIPP was adapted to the discrete time model of Flatland, with reservation tables approximating safe intervals. This allowed agents to plan paths that avoid *future* conflicts, and not just current ones

The theoretical contribution of SIPP is that it guarantees completeness, even if it does not guarantee consistency--in many cases a worthy trade for getting practical solutions.

### Reservation Tables and Re-planning

My implementation attempted to make use of **reservation tables**. Instead of storing continuous ranges, the tables stored sets of *forbidden* times as a time-indexed data structure that recorded which cells and edges are occupied by which agents. Before an agent would commit to a move, it would check whether the target cell is reserved at the desired timestep. Reservation tables are computationally simpler, but require explicit re-planning when malfunctions occur due to their dynamical nature. 
# Implementation Narrative

## Starter Code and Baseline Movement

The project began with a starter codebase provided for the Flatland environment. In this baseline, agents were initialized with start and target locations but lacked sophisticated pathfinding. Completing Question 1 confirmed that A* was sufficient in providing a solution to all test cases. I did not address Question 2. For Question 3, the agents did not move meaningfully toward their destinations at first. Instead, they either remained in place or moved one step before halting. An example of output data that was printed to a separate .txt file when I ran `quesiton3.py` see file "debug-data.txt" is included.

A key early challenge for Question 3 was understanding how movement worked in the rail grid. Unlike free grids, Flatland uses **bitmask-encoded transitions** to represent valid movements between cells. While I suspected such information to have value, it was difficult to effectively translate it into usable information. In addition, each cell stores a set of permissible directions depending on the track layout. This meant that naÃ¯ve grid logic (e.g., north, south, east, west moves) was insufficient. Correct agents movement required *both* reading `rail.get_transitions(x, y, dir)` and interpreting inbound versus outbound directions.

## Debugging Transitions and Directionality

The next obstacle was **directionality**. Flatland encodes tracks so that agents must enter cells from specific inbound directions before valid outbound moves are available. For example, an agent entering a curve from the north may only exit eastward, while entry from the west might lead south.

Initially, the planner failed because it assumed agents could always try any of the four directions. This often resulted in invalid move errors even when a path theoretically existed. My fix was to correctly track the **inbound direction** (`dir_in`), and after each move, the outbound direction  (which was used to invert via an **opposite-direction table**).

This seemingly small change was pivotal: once inbound and outbound consistency was maintained, agents could traverse multi-turn tracks. The debug logs clearly showed transitions being followed properly.

## Attempting BFS and A* Variants

With movement fixed, the next step was to implement a basic path search algorithm. Initially, this was a BFS that explored cells step by step until reaching the target. BFS produced valid shortest paths in terms of steps, but BFS's uninformed nature quickly revealed a key issue: multiple agents planned independently with no rule of thumb, causing severe conflicts.

To address efficiency, A* was introduced with a Manhattan distance heuristic. In single-agent scenarios, A* reliably found paths, but with multiple agents,  collisions ( especially in the form of deadlocks) persisted.

This stage demonstrated a fundamental theoretical gap: while A* is optimal for single agents where we assume away obstacles, they do not generalize to MAPF without additional conflict handling.
## Integrating CBS

I tried to replicate CBSâ€™s two-level structure: planning individual paths while detecting conflicts, and branching by introducing constraints.

In practice, this proved difficult. The branching process produced memory-intensive recursion, and managing the constraint tree in Python introduced even more technical issues. Specifically, the use of `heapq` with custom node objects I attempted to make (e.g.,`CBSNode`)  caused a lot of type-comparison errors. Fortunately, debugging revealed that the heap operations required more explicit ordering.
## Transition to Safe Interval Path Planning

The next turning point came with the decision to adopt **Safe Interval Path Planning (SIPP)**. Unlike CBS, SIPP proactively avoids collisions by reasoning about time with room to allow other imposed (and common) MAPF constraints. Each cell is associated with â€œsafe intervalsâ€ â€” periods during which the cell is free of conflicts.

Implementing SIPP required a significant amount of restructuring (and time) of my implementation. The critical change was in the **node expansion logic**. Rather than blindly generating neighbors, each move was only considered if the target cell was free at the intended timestep. This introduced temporal awareness directly into the search. Agents could also choose to wait in place if no moves were available.

## Reservation Table Design

I knew that my SIPP strategy needed a railway system conductor of sorts. This is where **reservation tables** came into play. The tables were implemented as lists of sets indexed by timestep, storing which positions or transitions were already occupied.

During planning, before agent $A$ committing to a move `(x, y) â†’ (nx, ny)`, the algorithm checked whether `(nx, ny)` was already in `occ_cells[t+1]`, and whether `((nx, ny), (x, y))` was in `occ_edges[t+1]`.

If either was true, the move was invalid. Otherwise, the reservation was recorded in both tables. This simple structure was highly effective at preventing obvious collisions in both pathing and re-planning.

On a small scale, the tables worked in principle but exposed a new layer of complexity: replanning must carefully synchronize with the agentsâ€™ partially executed paths. Otherwise, Python would flag run-time errors in my code. Debugging this involved implementing a lightweight `_Pseudo` helper class to unify agent states across planning calls.
## Debugging and Visualizing

I used a variety of debugging tools to understand the flatland architecture and the transition states of the grid. Though I must confess that during development, too much time was spent on analyzing flatland's base code--at the cost of analyzing and improving my own implementation. 

Below are the list of tools that I used:
1. **pytype** - print the return types of functions and the parameter types of class constructors
2. **pdb** - a run-time debugging tool to analyze function calls
3. **wrapper functions** - to tell python to write my desired outputs to a separate text file. I found this strategy to be extremely useful. You can find an example in the `strategies.py` file.

Throughout the vast majority of the assignment, I am sad to say that I was not attempting to visualize a dynamical grid with moving parts; and I believe that the lacking visuals  hindered my progress:

visualization using a whiteboard:
![[whiteboardimage2.jpeg]]
and using basic textual representation (found in the debug_data.txt file)

Diagramming revealed subtle but important bugs, such as failing to update inbound directions correctly after turns, or incorrectly recording reservations when agents waited. My debugging finally reached a point where agents could at least reach their destinations without collisions in simple test cases.

Larger scenarios with 25 or more agents was a different matter. The increase in objects made evaluator runtime grow significantly and decrease the success rate. Evaluator outputs showed that only a handful of agents reached their goals, with most getting stuck. At around 30 agents, runtime ballooned to sometimes over 40 minutes per test, and confirmed very low numbers in "Agents Done" and "DDL" in most cases. Even so, compared to my early results where no agent moved meaningfully, it was an improvement. 



---
# Results and Experiments

## Reflection on Results

Below is a listed summary of strengths/successes and weaknesses of my implementation that were detailed throughout the previous sections of this report:

#### **Strengths/Successes**

1. **Correct movement on tracks**  
    By fixing inbound/outbound direction handling, the system achieved a crucial milestone: agents could move reliably along realistic railway tracks.
    
2. **Collision avoidance through reservations**  
    The introduction of reservation tables, inspired by SIPP, successfully prevented simultaneous occupancy of cells and edge swaps. This mechanism ensured local safety and was a clear improvement over a simple time-aware A*.
    
3. **Iterative debugging methodology**  
    I demonstrated a disciplined debugging approach: printing transition markers, analyzing code base types and tracing runtime events, visualizing grids, and manually tracking agent steps. These methods were essential in diagnosing why the agents  attempted invalid transitions or stopped moving altogether.

#### **Weaknesses**

1. **Deadlocks in shared corridors**  
    This caused cycles of waiting where no agent advanced.
    
2. **Poor scalability**  
    As agent numbers increased,  the computational cost of maintaining large reservation tables became crippling.
    
3. **Incomplete conflict resolution**  
    Like basic CBS, the system did not provide a global mechanism to resolve conflicts once detected.
    
4. **Simplified SIPP implementation**  
    The adapted SIPP approach was not a fully safe interval planner, ironically due to my over-planning of the flatland code base. 

---

# Discussion

My development journey demonstrated both the utility and the ensure effective applications of the algorithms explored. From a theoretical perspective, BFS and A* are known to be optimal in single-agent domains but ineffective in multi-agent settings. My transition to SIPP matched theoretical expectations more closely, but the results reflected my rudimentary development strategy of SIPP. 

## Counterfactual Improvements

Below are some examples of how I could have improved my implementation:
##### Time Budget Trialing
A trial "time budget" allocation to instances so that when Prioritized Planning cannot find a solution, it will not waste an immense amount of time during the re-planning phase. This could have helped significantly with the server timeouts. (Thomas Nobes from the Ed Forums)
        
##### Incremental Re-planning
Instead of replanning full horizons for failed agents, the system could replan shorter windows around conflict zones. This would cut runtime and make the system more reactive.
    
##### Finer-grained heuristic functions
A more informed heuristic than Manhattan distance could improve efficiency. Rail-aware heuristics, such as precomputed shortest paths over the rail graph, would guide agents more intelligently (Phillips, M., & Likhachev, M., 2011) .
    
##### Reinforcement Learning: Tabular Q, Deep Q, and Beyond
I could have involved reward-shaping or machine learning methods to minimize bias pathfinding. It would have been interesting (and tremendously fun) to implement a reinforcement Q-Learning algorithm where I would have an online SARSA-Q policy and a Markovian-in-nature offline $\lambda$-Greedy policy where agents would Greedily-Learn Within the Limits of Infinite Exploration (GLIE). In this context, re-planning would be handled by a Zero-Sum or Cooperative game theoretic mechanism that the agents would play. I would then batch the training results and feed it back into the algorithm, resulting in the agents continuously refining their search methods and collision avoidance over time. (Skrynnik, 2022). A an even more nuanced and intriguing approach could possibly be found in Proximity Policy Optimization (Mohantany, 2020 & Yu, 2022)

##### Overall 
There are countless ways I (or anyone) could have improved my implementation--even to a scale that goes beyond anything that has been done before. As such is the nature of achieving better asymptotic behaviors via algorithm-strengthening or more robust modeling, all within the confines of Turing-complete computational systems. 

Armed with only around half a year's worth of consistent informal self-taught coding, while being completely unarmed with mathematics since my undergraduate algebra class in 2006, I believed the progress to be substantial. Brimming with passions for mastering my fields of interest in AI and simulation, I can only go up from here. 

# References

**Fioravantes, F.**Â (2025).Â _Solving multiagent path finding on highly centralized networks_. arXiv.Â [https://doi.org/10.48550/arXiv.2412.09433](https://doi.org/10.48550/arXiv.2412.09433)

**Geft, T.**Â (2023).Â *Fine-grained complexity analysis of multi-agent path finding on 2D grids*.Â _Artificial Intelligence_,Â *314*, 103822.Â [https://doi.org/10.1016/j.artint.2022.103822](https://doi.org/10.1016/j.artint.2022.103822)

**Li, J., Chen, Z., Zheng, Y., Chan, S.-H., Harabor, D., Stuckey, P. J., Ma, H., & Koenig, S.**Â (2021).Â _Scalable rail planning and replanning: Winning the 2020 Flatland challenge_. InÂ _Proceedings of the International Conference on Automated Planning and Scheduling_Â (Vol. 31, pp. 517-525).

**Nebel, B.**Â (2023).Â _On the computational complexity of multi-agent pathfinding on directed graphs_.Â _Journal of Artificial Intelligence Research_,Â *76*, 1513-1552.Â [https://doi.org/10.1613/jair.1.14201](https://doi.org/10.1613/jair.1.14201)

**Phillips, M., & Likhachev, M.**Â (2011).Â _SIPP: Safe interval path planning for dynamic environments_. InÂ _Proceedings of the IEEE International Conference on Robotics and Automation_Â (pp. 5628-5635). IEEE.Â [https://doi.org/10.1109/ICRA.2011.5980306](https://doi.org/10.1109/ICRA.2011.5980306)

**Skrynnik, A., Yakovleva, A., & Davydov, V.**Â (2022).Â _Hybrid policy learning for multi-agent pathfinding_. InÂ _Proceedings of the 21st International Conference on Autonomous Agents and Multiagent Systems_Â (pp. 1179-1187).

Mohanty, S. (2020).Â _Flatland-RL : Multi-Agent Reinforcement Learning on Trains_. ArXiv.org. https://arxiv.org/abs/2012.05893

â€ŒYu, C.(2022).Â _The Surprising Effectiveness of PPO in Cooperative, Multi-Agent Games_. ArXiv.org. https://doi.org/10.48550/arXiv.2103.01955

â€Œ