
---

# **Study Sheet: Linear Models for Regression**

#### **1. Core Concept: Regression vs. Classification**

*   **Regression:** Predicts a **continuous** target value (e.g., house price, age, weight).
*   **Classification:** Predicts a **discrete** class label (e.g., spam/ham, dog/cat).

# Model Structure
## 2. The Linear Regression Model

The model is **linear in its parameters**, not necessarily in its input features. This is the key definition.

*   **General Form:** $y(x, 𝐰) = w₀ + w₁φ₁(x) + w₂φ₂(x) + ... + w_Mφ_M(x)$
    *   $𝐰 = [w₀, w₁, ..., w_M]ᵀ$ is the *parameter* or *weight* vector.
    *   $φ_j(x)$ are *basis functions* or *feature functions*. They transform the input $x$: $$φ_j(x) = x^j$$ for polynomials, $$φ_j(x) = exp(\frac{-(x-μ_j)²}{2s²})$$for Gaussians
    
	 The model's flexibility and ability to fit nonlinear data comes from these (often nonlinear) basis functions, while the learning problem remains tractable due to linearity in `𝐰`.

$y(x,w)=w_0+\sum_{j=0}^{M-1} w_j \phi_j (x) = w^T\phi (x)$
### Vector Form (Compact Notation):

   *   Define a feature vector $φ(x) = [1, φ₁(x), φ₂(x), ..., φ_M(x)]ᵀ$. The `1` corresponds to the bias term `w₀`.
   *   The model becomes: $y(x, 𝐰) = 𝐰ᵀφ(x)$

## 3. Learning the Parameters: The Objective Function

*The goal is to find the weight vector* `𝐰` *that best fits the training data* `{x_n, t_n}_{n=1}^N`.

### Sum-of-Squares Error Function
    $$J(𝐰) = (1/2) * Σ_{n=1}^N [t_n - 𝐰ᵀφ(x_n)]²$$
	  This measures the "misfit" between the model's predictions `y(x_n, 𝐰)` and the true targets $t_n$

#### Connection to Maximum Likelihood (ML)
  **Assumption:** Targets `t` are generated by the model with additive Gaussian noise: $t = y(x, 𝐰) + ε$, where $ε ~ N(0, σ²)$.
    *   This implies: $p(t | x, 𝐰, σ²) = N(t | y(x, 𝐰), σ²)$
    *   The **likelihood** of the entire dataset (assuming i.i.d. data) is the product of these probabilities.
    *   **Key Result:** **Maximizing this likelihood is equivalent to minimizing the sum-of-squares error `J(𝐰)`.** This provides a rigorous probabilistic justification for using the squared error.

## 4. Optimizing the Objective: Finding the Best 𝐰

### Method 

Set the gradient of the error function `∇J(𝐰)` to zero and solve for `𝐰`.
    *   $∇J(𝐰) = 0$ leads to a system of linear equations.

  **1. Closed-Form Solution (The Normal Equation):** $𝐰* = (ΦᵀΦ)⁻¹Φᵀ𝐭$
    *   `Φ` is the *design matrix* (`N x M`), where *each row is the feature vector* $φ(x_n)ᵀ$ for a data point.
    *   $𝐭 = [t₁, t₂, ..., t_N]ᵀ$ is the *target vector*.
		**Pros:** Exact, one-step solution.
		**Cons:** Computationally expensive for large `M` (number of features). Calculating the matrix inverse $(ΦᵀΦ)⁻¹$ is an $O(M³)$ operation.

**2. Iterative Solution: Gradient Descent (GD)**
*   Start with a random guess for `𝐰` and iteratively move in the direction of the steepest decrease of $J(𝐰)$.
*   **Update Rule:** $𝐰^{new} = 𝐰^{old} - η ∇J(𝐰^{old})$
    *   `η` is the *learning rate* (step size).
    *   $∇J(𝐰) = -Σ_{n=1}^N [t_n - 𝐰ᵀφ(x_n)]φ(x_n)$ is the *gradient*.
#### Batch Gradient Descent 
Uses the **entire** training set to compute the gradient for each update. Computationally heavy per step.
##### Stochastic Gradient Descent (SGD) 
A more efficient variant.
    *   **Idea:** Approximate the true gradient using a **single, randomly chosen data point** (or a *mini-batch*).
    *   **Update Rule:** $𝐰^{new} = 𝐰^{old} - η [t_n - 𝐰ᵀφ(x_n)]φ(x_n)$
    *   **Pros:** Much *faster per update*. Can *escape shallow local minima* (crucial for non-convex problems in deep learning).
    *   **Cons:** *Noisy updates* mean the path to the minimum is not smooth. Requires careful tuning of `η`.

## 5. The Problem of Overfitting and Regularization

A model with *high flexibility* (many basis functions) can learn the noise in the training data, leading to poor performance on new data (overfitting).

### Solution 
Add a *regularization term* $λ Ω(𝐰)$ to the error function to penalize large weight values.
    *   **New Objective:** $J̃(𝐰) = J(𝐰) + λ Ω(𝐰)$
    *   `λ` is the *regularization parameter*: controls the trade-off between fitting the data (`J(𝐰)`) and keeping weights small (`Ω(𝐰)`).
    *   `Ω(𝐰)` is the *regularizer*.

*   **Choosing `λ`:** Use *validation* (e.g., k-fold cross-validation). Train models with different `λ` values and pick the one that performs best on a held-out validation set.

#### Common Regularizers:
 **L2 Regularization (Ridge Regression):** $Ω(𝐰) = (1/2)||𝐰||₂² = (1/2)Σ w_j²$
        *   **Effect:** Tends to produce models with many small, non-zero weights. The solution remains in closed form: $𝐰* = (ΦᵀΦ + λI)⁻¹Φᵀ𝐭$.
        *   **Properties:** Differentiable, efficient to optimize.
**L1 Regularization (Lasso):** $Ω(𝐰) = ||𝐰||₁ = Σ |w_j|$
        *   **Effect:** Tends to produce *sparse models*—it drives some weights **exactly to zero**, effectively performing **feature selection**. The features with non-zero weights are deemed the most important.
        *   **Properties:** Not differentiable at 0 (requires `sub-gradient` methods for optimization).

## 6. Key Terminology

*   **Basis/Feature Functions (`φ_j(x)`):** Non-linear transformations of the input that provide model flexibility.
*   **Design Matrix (`Φ`):** Matrix of all feature vectors for all training points.
*   **Maximum Likelihood (ML):** A principle for parameter estimation that justifies the use of the sum-of-squares error.
*   **Gradient Descent (GD):** An iterative optimization algorithm.
*   **Stochastic GD (SGD):** A faster, noisy variant of GD using data subsets.
*   **Overfitting:** Modeling the noise in the training data, leading to poor generalization.
*   **Regularization:** Technique to prevent overfitting by penalizing model complexity.
*   **Ridge Regression:** Linear regression with **L2 regularization**.
*   **Lasso:** Linear regression with **L1 regularization**.

---
**How to Use This Sheet:**
1.  **Understand the Derivation:** Be able to explain why maximizing the likelihood under Gaussian noise leads to minimizing the sum-of-squares error.
2.  **Practice the Math:** Manually compute the closed-form solution `(ΦᵀΦ)⁻¹Φᵀ𝐭` for a tiny dataset (e.g., 2-3 points, 1-2 features).
3.  **Perform GD/SGD by Hand:** For a simple function (e.g., `J(w) = w²`), calculate a few steps of GD and SGD to see how the parameter updates work.
4.  **Contrast L1 vs. L2:** Be able to explain the fundamental difference in the solutions they produce (dense vs. sparse weights) and why this happens.
5.  **Connect Concepts:** Link the idea of model flexibility (number of basis functions) to overfitting and see regularization as the solution.