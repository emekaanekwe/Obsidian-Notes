
---

### **Machine Learning Exam Study Sheet: Classification Models**

#### **1. Overview: From Perceptron to Probabilistic Models**
*   **Perceptron (Last Lecture):** A *non-probabilistic discriminative* model. It finds a decision boundary to separate classes but does not provide a probability for its predictions.
*   **This Lecture:** Introduces *probabilistic* models for classification.
    1.  **Logistic Regression:** A *probabilistic discriminative* model.
    2.  **Generative Models:** A *probabilistic generative* approach.

---

### **2. Logistic Regression (Probabilistic Discriminative Model)**

#### **Core Idea**
Directly models the conditional probability `P(y | x)` of the class label `y` given the input features `x`. It outputs not just a class label, but the **probability** that the input belongs to a class. This is crucial for quantifying prediction uncertainty.

#### **Mathematical Formulation**
1.  **Linear Score:** First, compute a linear combination of the input features.
    `z = wᵀx + b`
    where:
    *   `w` is the **weight vector** (parameters to learn).
    *   `x` is the **input feature vector**.
    *   `b` is the **bias** term.
    *   `z` is an unbounded real number.

2.  **Logistic (Sigmoid) Function:** Squash the linear score `z` into the range `[0, 1]` to interpret it as a probability.
    `σ(z) = 1 / (1 + e^{-z})`
    *   Properties: `σ(0) = 0.5`, `σ(∞) ≈ 1`, `σ(-∞) ≈ 0`.
    *   Its derivative is simple: `dσ(z)/dz = σ(z)(1 - σ(z))`.

3.  **Final Model:** The probability that an input `x` belongs to Class 1 (e.g., "tuna") is:
    `P(C₁ | x) = σ(wᵀx + b) = 1 / (1 + e^{-(wᵀx + b)})`
    The probability for Class 2 (e.g., "bus") is simply:
    `P(C₂ | x) = 1 - P(C₁ | x)`

#### **Decision Boundary**
*   The model predicts Class 1 if `P(C₁ | x) > 0.5` and Class 2 otherwise.
*   Since `σ(z) = 0.5` when `z = 0`, the **decision boundary** is the set of points `x` where:
    `wᵀx + b = 0`
*   This is a **linear** (straight line, plane, or hyperplane) boundary in the feature space.

#### **Parameter Learning: Maximum Likelihood & SGD**
*   **Training Data:** `{ (x₁, t₁), (x₂, t₂), ..., (x_N, t_N) }` where `tᵢ ∈ {0, 1}` (0 for Class 2, 1 for Class 1).
*   **Likelihood Function:** The probability of the observed data given the parameters `w`.
    `L(w) = Π [P(C₁|xᵢ)]^{tᵢ} * [1 - P(C₁|xᵢ)]^{1-tᵢ}`
    *   For a point labeled `1`, we want `P(C₁|x)` to be high.
    *   For a point labeled `0`, we want `1 - P(C₁|x)` (i.e., `P(C₂|x)`) to be high.
*   **Log-Likelihood (to maximize):** Easier to work with sums than products.
    `ln L(w) = Σ [ tᵢ ln(σ(wᵀxᵢ)) + (1 - tᵢ) ln(1 - σ(wᵀxᵢ)) ]`
*   **Optimization:** The derivative of the log-likelihood (or the negative log-likelihood, the *loss*) does not have a closed-form solution. We use **Stochastic Gradient Descent (SGD)**.
    *   **SGD Update Rule:**
        `w^{(new)} = w^{(old)} - η * ∇Eᵢ`
        where `η` is the learning rate and `∇Eᵢ` is the gradient of the error for a single data point `i`.
    *   The gradient for a single point has a remarkably simple form:
        `∇Eᵢ = (σ(wᵀxᵢ) - tᵢ) * xᵢ`

---

### **3. Generative Models for Classification**

#### **Core Idea**
Instead of modeling `P(y | x)` directly, generative models model the **data generation process**. They learn:
1.  **Class Prior, P(y):** The probability of a class before seeing any data (e.g., how common is "tuna" vs. "bus"?).
2.  **Class-Conditional Density, P(x | y):** The distribution of input features *within each class* (e.g., what do "tuna" images typically look like?).

To perform classification, we use **Bayes' Theorem** to invert these probabilities:
`P(y | x) = [P(x | y) * P(y)] / P(x)`
Since `P(x)` is a normalizing constant equal to `Σ P(x | y)P(y)` for all classes, we predict the class `y` that maximizes the **numerator**:
`y_pred = argmax_y [ P(x | y) * P(y) ]`

#### **Why Generative?**
*   You can **generate (synthesize)** new data points `x` for any class `y` by sampling from `P(x | y)`. This is the foundation of Generative AI.

#### **Modeling the Components (Gaussian Assumption)**
1.  **Class Prior, P(Cₖ):**
    *   For a binary problem, modeled by a single parameter `φ`.
    `P(C₁) = φ`, `P(C₂) = 1 - φ`
    *   **Learning (MLE):** `φ = (Number of Class 1 examples) / (Total examples)`

2.  **Class-Conditional Density, P(x | Cₖ):**
    *   Modeled as a **Gaussian (Normal) Distribution**.
    *   For a **single feature** (univariate):
        `P(x | Cₖ) = N(x | μₖ, σₖ²) = (1 / √(2πσₖ²)) * exp( - (x - μₖ)² / (2σₖ²) )`
        Parameters to learn for each class: mean `μₖ` and variance `σₖ²`.
    *   For **multiple features** (multivariate, `x` is a vector):
        `P(x | Cₖ) = N(x | μₖ, Σₖ) = (1 / ( (2π)^{D/2} |Σₖ|^{1/2} )) * exp( -½ (x - μₖ)ᵀ Σₖ⁻¹ (x - μₖ) )`
        Parameters to learn for each class: mean vector `μₖ` and covariance matrix `Σₖ`.

#### **Learning the Parameters (MLE)**
*   The parameters (`φ`, `μ₁`, `σ₁²`, `μ₂`, `σ₂²` for univariate) are learned by **maximizing the likelihood** of the training data.
*   **Closed-Form Solutions exist:**
    *   **Means (μₖ):** The mean (or average vector) of all training examples in class `k`.
        `μ₁ = (1/N₁) Σ_{n: tₙ=1} xₙ`
    *   **Covariance (Σₖ):** The empirical covariance matrix of the data in class `k`. Often, we assume a **shared covariance matrix** `Σ` for both classes to simplify the model.
        `Shared Σ = (N₁/N) * S₁ + (N₂/N) * S₂`
        where `Sₖ` is the covariance matrix calculated solely from the data in class `k`.

#### **The Decision Boundary**
*   If the **covariance matrices `Σ₁` and `Σ₂` are different**, the decision boundary `P(C₁|x) = P(C₂|x)` is a **quadratic** function (e.g., ellipse, parabola, hyperbola).
*   If a **shared covariance matrix `Σ` is used**, the quadratic terms cancel out. The decision boundary simplifies to a **linear** function:
    `wᵀx + w₀ = 0`
    where `w = Σ⁻¹(μ₁ - μ₂)` and `w₀` is a constant term involving the means and the class prior `φ`. This is a linear classifier.

---

### **4. Handwritten Example: Generative Model (Univariate Gaussian)**

**Problem:** Predict if a student passes (`C₁=1`) or fails (`C₂=0`) an exam based on a single feature: hours studied (`x`). Training data: 3 students passed (studied 6, 7, 8 hrs), 2 failed (studied 1, 2 hrs).

**Task:** Learn the generative model parameters (`φ`, `μ₁`, `σ₁²`, `μ₂`, `σ₂²`) using MLE.

**Solution:**

**1. Learn Class Prior P(Cₖ):**
*   `N = 5` total students
*   `N₁ = 3` passed, `N₂ = 2` failed
*   `P(C₁) = φ = N₁ / N = 3/5`
*   `P(C₂) = 1 - φ = 2/5`

**2. Learn Class-Conditional P(x | Cₖ):** (Assume univariate Gaussian)
*   **For Class 1 (Passed):** Data: `x = {6, 7, 8}`
    *   Mean `μ₁ = (6 + 7 + 8) / 3 = 21 / 3 = 7.0`
    *   Variance `σ₁² = [ (6-7)² + (7-7)² + (8-7)² ] / 3 = [1 + 0 + 1] / 3 = 2/3 ≈ 0.667`
*   **For Class 2 (Failed):** Data: `x = {1, 2}`
    *   Mean `μ₂ = (1 + 2) / 2 = 3 / 2 = 1.5`
    *   Variance `σ₂² = [ (1-1.5)² + (2-1.5)² ] / 2 = [0.25 + 0.25] / 2 = 0.5 / 2 = 0.25`

**3. Make a Prediction for a new student who studied `x=5` hours:**
We use Bayes' Rule. Since `P(x)` is the same for both classes, we compare the numerators:
`P(C₁ | x=5) ∝ P(x=5 | C₁) * P(C₁)`
`P(C₂ | x=5) ∝ P(x=5 | C₂) * P(C₂)`

Calculate the Gaussian probabilities (using the PDF formula):
*   `P(x=5 | C₁) = (1/√(2π*(2/3))) * exp( - (5-7)² / (2*(2/3)) ) ≈ (1/2.047) * exp( -4 / (4/3) ) ≈ 0.489 * exp(-3) ≈ 0.489 * 0.0498 ≈ 0.0243`
*   `P(x=5 | C₂) = (1/√(2π*0.25))) * exp( - (5-1.5)² / (2*0.25) ) ≈ (1/1.253) * exp( -12.25 / 0.5 ) ≈ 0.798 * exp(-24.5) ≈ 0.798 * 2.12e-11 ≈ 1.69e-11`

Now multiply by the priors:
*   `P(C₁ | x=5) ∝ 0.0243 * (3/5) = 0.0243 * 0.6 = 0.0146`
*   `P(C₂ | x=5) ∝ 1.69e-11 * (2/5) = 1.69e-11 * 0.4 = 6.76e-12`

`0.0146 > 6.76e-12`. Therefore, the model predicts the student **passed** (`C₁`). The probability is `0.0146 / (0.0146 + 6.76e-12) ≈ 1.0`.

---
### **5. Summary & Key Comparisons**

| Feature | **Logistic Regression (Discriminative)** | **Generative Model** |
| :--- | :--- | :--- |
| **Models** | `P(y | x)` directly | `P(x | y)` and `P(y)` |
| **Goal** | Find decision boundary | Model data generation process |
| **Output** | Class probability | Class probability + Can generate new data |
| **Boundary** | Linear (by design) | Linear (if shared Σ) or Quadratic |
| **Data Efficiency** | Often needs less data | Often needs more data |
| **Learning** | SGD (no closed form) | MLE (closed form for Gaussians) |
| **Parameters** | Weight vector `w`, bias `b` | Means `μₖ`, covariances `Σₖ`, prior `φ` |

Of course. This textbook chapter provides a structured and formal presentation of the classification concepts introduced in the lecture. I will synthesize the information from both sources into a single, comprehensive, and exam-focused study sheet.

---

### **Machine Learning Exam Study Sheet: Linear Models for Classification**

#### **1. Core Concepts & Approaches**
*   **Goal:** Assign an input vector `x` to one of `K` discrete classes `C_k`.
*   **Key Difference from Regression:** The output variable is discrete (class labels) instead of continuous.
*   **Three Main Approaches:**
    1.  **Discriminative Models:** Non-probabilistic. Directly learn a **decision boundary** that separates classes. (e.g., Perceptron).
    2.  **Probabilistic Discriminative Models:** Model the **posterior probability** `P(C_k | x)` directly. (e.g., Logistic Regression).
    3.  **Probabilistic Generative Models:** Model the **data generation process** by learning the **class-conditional densities** `P(x | C_k)` and **class priors** `P(C_k)`, then use Bayes' Theorem to find `P(C_k | x)`.

#### **2. The Geometry of Linear Classification**
*   **Decision Boundary:** A surface that separates the input space into decision regions. For linear models, this is a **linear function** of the input `x`.
*   In 2D: A **line** defined by `wᵀx + w₀ = 0`.
*   In D-dimensions: A **(D-1)-dimensional hyperplane**.
*   **Linear Separability:** A dataset is linearly separable if a hyperplane exists that can perfectly separate all data points of different classes.

#### **3. Discriminative Models: The Perceptron**
*   **Model:** A generalized linear model with a step function as the activation.
    `y(x) = f(wᵀϕ(x))` where `f(u) = { +1 if u ≥ 0; -1 otherwise }`
    *   `ϕ(x)` can be a basis function transformation (e.g., polynomial features). If `ϕ(x) = x`, it's a linear perceptron.
*   **Prediction:** Assign `x` to class `C₁` if `y(x) = +1`, and to `C₂` if `y(x) = -1`.
*   **Training Objective:** Minimize the number of misclassified points. A point `(x_n, t_n)` is misclassified if `wᵀϕ(x_n) * t_n < 0`.
*   **Perceptron Learning Algorithm (SGD):**
    1.  Initialize `w = 0`.
    2.  For each data point `(x_n, t_n)`:
        *   If `wᵀϕ(x_n) * t_n < 0` (misclassified), update: **`w := w + η ϕ(x_n) t_n`**
        *   If correctly classified, do nothing.
    3.  Iterate until all points are correctly classified or a stopping condition is met.
*   **Properties:**
    *   **Convergence:** If the data is linearly separable, the algorithm is guaranteed to find a perfect solution (but may take many iterations).
    *   **Non-Separable Data:** The algorithm will not converge and may cycle indefinitely.
    *   **Sensitivity:** The solution depends on the order in which data points are processed.

#### **4. Probabilistic Generative Models**
*   **Core Idea:** Model the distribution of the data *from each class*. Learn `P(x | C_k)` and `P(C_k)`, then use **Bayes' Theorem** for prediction:
    `P(C_k | x) = [P(x | C_k) P(C_k)] / P(x) ∝ P(x | C_k) P(C_k)`
*   **Prediction Rule:** Assign `x` to the class `C_k` that maximizes `P(x | C_k) P(C_k)`.
*   **Why Generative?** You can **generate (synthesize)** new data points `x` by sampling from `P(x | C_k)`.
*   **Cost:** Typically has **more parameters** than a discriminative model, making it more prone to overfitting.

##### **4.1 Gaussian Generative Classifier (Same Covariance)**
*   **Assumption:** Class-conditional densities are Gaussian with **class-specific means** `μ_k` and a **shared covariance matrix** `Σ`.
    `P(x | C_k) = N(x | μ_k, Σ)`
*   **The Decision Boundary:** Under this assumption, the decision boundary `P(C₁|x) = P(C₂|x)` becomes **linear**. The function `a = ln[P(C₁|x)/P(C₂|x)]` simplifies to:
    `a = wᵀx + w₀`
    where `w = Σ⁻¹(μ₁ - μ₂)` and `w₀` is a constant involving the means and priors.
*   **The Posterior:** This leads to a posterior probability that is a logistic sigmoid:
    `P(C₁ | x) = σ(a) = σ(wᵀx + w₀) = 1 / (1 + exp(-a))`
*   **Parameter Learning (MLE):** Given data, learn parameters by maximizing the likelihood.
    *   **Class Prior:** `P(C₁) = φ = N₁ / (N₁ + N₂)` (Fraction of points in class 1).
    *   **Class Means:** `μ₁ = (1/N₁) Σ_{n: t_n=1} x_n`, `μ₂ = (1/N₂) Σ_{n: t_n=0} x_n` (Mean of points in each class).
    *   **Shared Covariance:** `Σ = (N₁/N) S₁ + (N₂/N) S₂` (Weighted average of class covariances).
        `S_k = (1/N_k) Σ_{n in C_k} (x_n - μ_k)(x_n - μ_k)ᵀ`

#### **5. Probabilistic Discriminative Models: Logistic Regression**
*   **Core Idea:** Directly model the posterior probability `P(C₁ | x)` using the functional form derived from the generative model, but **learn its parameters directly** from the data.
*   **Model:** `P(C₁ | x) = σ(wᵀx) = 1 / (1 + exp(-wᵀx))`
*   **Why Discriminative?** Fewer parameters. For a `D`-dimensional `x`:
    *   **Generative:** ~`D²/2` parameters (for `Σ`) + `2D` (for `μ₁, μ₂`) + 1 (for `φ`) → **Quadratic** in `D`.
    *   **Logistic Regression:** `D` parameters (for `w`) → **Linear** in `D`. This reduces overfitting.
*   **Parameter Learning (MLE):** Maximize the log-likelihood of the data.
    *   **Likelihood:** `L(w) = Σ_n [ t_n ln(y_n) + (1 - t_n) ln(1 - y_n) ]` where `y_n = σ(wᵀx_n)`.
*   **Optimization:** There is **no closed-form solution**. Must use iterative methods like **Stochastic Gradient Descent (SGD)**.
*   **Logistic Regression SGD Update Rule:**
    `w := w - η ∇E(w) = w + η (t_n - y_n) x_n`
    *   Intuition: The update is proportional to the **error** `(t_n - y_n)`. The weights are pushed more strongly for larger errors.

#### **6. Summary & Key Comparisons**

| Feature | **Perceptron (Discriminative)** | **Generative Model** | **Logistic Regression (Discrim.)** |
| :--- | :--- | :--- | :--- |
| **Output** | Class label (-1, +1) | Probability `P(C_k\|x)` | Probability `P(C₁\|x)` |
| **Model** | `sign(wᵀx)` | `P(x\|C_k)P(C_k)` | `σ(wᵀx)` |
| **Learning** | SGD on misclassification | MLE (closed-form for Gaussians) | MLE (SGD on log-likelihood) |
| **Parameters** | `w` | `μ₁, μ₂, Σ, φ` (~`D²`) | `w` (`D`) |
| **Pros** | Simple, guaranteed convergence if separable | Can generate data, probabilistic | Fewer parameters, often better performance |
| **Cons** | Doesn't converge if not separable, no probabilities | Many parameters, can overfit | Requires iterative optimization |

---

### **7. Handwritten Example: Generative vs. Discriminative Learning**

**Problem:** Predict if a student passes (`C₁=1`) or fails (`C₂=0`) based on hours studied (`x`). Data: `(1, 0), (2, 0), (3, 1), (4, 1)`.

**Solution:**

**1. Generative Approach (Gaussian, shared variance):**
*   **Priors:** `P(C₁) = 2/4 = 0.5`, `P(C₂) = 2/4 = 0.5`
*   **Means:** `μ₁ = (3+4)/2 = 3.5`, `μ₂ = (1+2)/2 = 1.5`
*   **Variances:** Calculate within-class variance and average them.
    *   `Var(C₁) = ((3-3.5)² + (4-3.5)²)/(2-1) = (0.25+0.25)/1 = 0.5`
    *   `Var(C₂) = ((1-1.5)² + (2-1.5)²)/(2-1) = (0.25+0.25)/1 = 0.5`
    *   **Shared Variance:** `σ² = (2/4)*0.5 + (2/4)*0.5 = 0.5`
*   **Class-Conditionals:**
    `P(x|C₁) = N(x | 3.5, 0.5)`, `P(x|C₂) = N(x | 1.5, 0.5)`
*   **Prediction for a new student with `x=2.5`:**
    *   Calculate both numerators: `P(x|C₁)P(C₁)` and `P(x|C₂)P(C₂)`
    *   `P(C₁|x=2.5) ∝ N(2.5|3.5, 0.5) * 0.5`
    *   `P(C₂|x=2.5) ∝ N(2.5|1.5, 0.5) * 0.5`
    *   Since `N(2.5|1.5, 0.5) > N(2.5|3.5, 0.5)`, the model predicts **Fail (`C₂`)**.

**2. Discriminative Approach (Logistic Regression):**
*   **Model:** `P(C₁|x) = σ(w₀ + w₁x)`
*   **Learning:** Use SGD to maximize the likelihood of the data `{(1,0), (2,0), (3,1), (4,1)}` by finding `w₀` and `w₁`.
*   **Result:** The learned function will be a smooth S-curve. For `x=2.5`, it will output a probability `P(C₁|2.5)` likely around `0.3-0.4`, also leading to a prediction of **Fail (`C₂`)**.

**Conclusion:** Both models agree on the prediction, but were arrived at through fundamentally different approaches: one by modeling the data distribution, the other by directly modeling the decision boundary.

Hi Kevin,

Yes, that make sense. While I may have an idea on how to implement TXA* for example, I'm struggling trying to figure out "where to start", if that makes sense. 

I'll use some photos to give you an idea of my thought process:

For question 2:



Okay, so I look at the function get_path and look carefully at the params. I see that we have tuples for start and goals, ints for directions, identifying agents and time, and GridTransitionMap for the railway cells that I recall seeing:







So, it seems I can to look into GridTransitionMap in order to understand how the transitions work. Looking at that file/module, I see:



So I'm guessing that I need to do something with that parameter when agents are trnsitioning from one state to another. It looks like I can also call functions like get_transitions that I can use to maybe get possible states that the agents can transition to next...



Okay, so maybe I can start writing some code. I will go back to the question3.py file, and see if I can write out the get_path function...

 # initialize path list
    path = []
    loc = start
    # direction == orientation
    direction = start_direction
    
    # Ummm get the grid transitions? 
    grid = GridTransition


But wait! Won't the grid sizes, railways, etc. be instantiated during testing? I won't be able to do much if the dimensions are not defined. So what now...

Looking back at the transition_map.py file, I see the class TransitionMap, and it looks pretty barren. I see some raise NotImplementedError() returns! 

So, maybe I can build my own grid? Hmm, how do I do that while making sure the tiles make sense? But I thought we were just supposed to implement the algorithm for the agents... Am I looking in the wrong place or thinking about this incorrectly?  If I am, then which file should I be paying attention to? 

Now what do I do?????

---

Sorry if this is long, but I hope it gives you an idea of how my investigations lead to me scratching my head.