# PART A: MULTIPLE CHOICE (12 QUESTIONS, 25 MARKS)
## Question 1
Consider the following implementation of a feedforward NN. 
```python
dnn_model = Sequential()
dnn_model.add(Dense(units=20, input_shape=(10,), activation='relu'))
dnn_model.add(Dense(units=40, activation='relu'))
```

What is the total number of parameters?

Select one:
a.
1060
b.
1070
c.
1000
d.
1020
e.
1050

## Question 2
Let $f(w)= 3w2 - 4w + 10$. Assume that we use gradient descent with the learning rate $η=0.05$ to solve $min_w f(w)$. At the iteration t, we are at $w_t=2$. What is the value of $w_t+1$ at the next iteration?
Select one:
a.
1.6
b.
1.9
c.
1.7
d.
2.0
e.
1.8

## Question 3

Consider the optimization problem:
$$$$

with the model parameter $\theta$ and $D={(x_1, y_1 ),…,(x_N, y_N)}$ is a training set. Let us sample a batch of
indices $i_1,…,i_b$ uniformly from ${1,…,N}$. Which statement is correct about the update rule of stochastic gradient descent?

a.
$$\theta_{t+1}=\theta_t-\frac{\eta}{b}\sum^{b}_{k=1}\nabla_{\theta}\ l(x_{i_k};y_{i_k};\theta_t)$$
b.
$$\theta_{t+1}=\theta_t+\frac{\eta}{b}\sum^{N}_{i=1}\nabla_{\theta}\ l(x_{i};y_{i};\theta_t)$$
c.
$$\theta_{t+1}=\theta_t-\frac{1}{b}\sum^{b}_{k=1}\nabla_{\theta}\ l(x_{i_k};y_{i_k};\theta_t)$$
d.
$$\theta_{t+1}=\theta_t+\frac{\eta}{b}\sum^{b}_{k=1}\nabla_{\theta}\ l(x_{i_k};y_{i_k};\theta_t)$$
## Question 4
Given a 3D input tensor with shape [64, 64, 3] over which we apply a conv2D with 15 filters each of which has shape [5,5,3], strides [3,3], and padding same. What is the shape of the output tensor?

Select one:
a.
[21, 21, 15]
b.
[20,20,15]
c.
[22, 22, 15]
d.
[23,23,15]

## Question 5
Consider an image classification task with five classes {cat=1, dog=2, lion=3, flower=4, cow=5}. Consider an image x. Assume that a Convolutional Neural Network gives prediction probabilities f(x)= [0.4, 0.2, 0.1, 0.2, 0.1] and categorial ground-truth label of x is flower. What is the cross-entropy loss
suffered by this prediction?

Select one:
a.
$-log 0.1$
b.
$-log 0.2$
c.
$log 0.1$
d.
$log 0.2$

## Question 6
Assume that we have 4 classes in {cat = 1, dog = 2, lion = 3, monkey = 4}. Given a data example with ground-truth label dog, assume that a feed-forward NN gives discriminative scores to this x as h1=-3, h2=10, h3=5, h4=-1. What is the probability to predict x as lion or p(y=lion∣ x)?

Select one:
a.
1
b.
$$\frac{e^5}{e^{-3}+e^{10}+e^5+e^{-1}}$$
c. 
$$\frac{e^{-3}}{e^{-3}+e^{10}+e^5+e^{-1}}$$
d.
$$\frac{e^{10}}{e^{-3}+e^{10}+e^5+e^{-1}}$$

## Question 7
Assume that the tensor before the last tensor of a CNN has shape [64, 32, 32, 10] and we apply 20 filters each of which has the shape [5,5,10] and strides= [3,3] with padding = ‘same’ to obtain the last tensor. What is the shape of the output tensor?

Select one:
a.
[64, 10, 10, 20]
b.
[64, 12, 12, 20]
c.
[64, 11, 11, 20]
d.
[64, 10, 10, 10]

## Question 8
Given a DL model f(x;θ) parameterized by θ where f(x;θ) represents the prediction probabilities of x associated with a ground-truth label y∈{1,…,M} , we find an adversarial example by:
$$x_{adv}=argmax_{x'\in B_{\in (x)}} \ l(f(x';\theta), y)$$
Which statements are correct?

Select one or more:
a.
We maximally increase the chance to predict x with label y.
b.
We maximally increase the chance to predict x with any else label y′≠y.
c.
It is an untargeted attack.
d.
It is a targeted attack.
e.
We maximally decrease the chance to predict x with label y.

## Question 9
Given a skip-gram model with vocabulary size 500 and embedding size 150, we consider a pair of target and context words with indices 2 and 8 respectively. Let U and V be two weight matrices connecting the input to hidden layers and hidden to output layers. What statements are correct?

Select one or more:
a.
Shape of U is [500,500] and shape of V is [150,150]
b.
Shape of U is [500,150] and shape of V is [150,500]
c.
Input to the network is one-hot vector 18.
d.
The hidden value h is the row 2 of the matrix U.
e.
Input to the network is one-hot vector 12.
f.
The hidden value h is the row 8 of the matrix U

## Question 10
How to train a denoising auto-encder with encoder $f_{\theta}$ and decoder $g_{\theta}$?

4 -- noise --> pixelated 4 --> encoder --> pixels --> decoder --> 4

Select one or more:

a.
$$\underset{\theta, \phi}{min}E_{x~P}[E_{x'~N(x,\eta I)}[d(x, g_{\phi}(f_{\theta}(x')))]$$

b.
$$\underset{\theta, \phi}{min}E_{x~P}[E_{\epsilon~N(0,\eta I)}[d(x, f_{\theta}(g_{\phi}(x+\epsilon)))]$$
c.
$$\underset{\theta, \phi}{min}E_{x~P}[E_{x'~N(x,\eta I)}[d(x, g_{\phi}(f_{\theta}(x+\epsilon)))]$$
d.
$$\underset{\theta, \phi}{min}E_{x~P}[E_{x'~N(x,\eta I)}[d(x, f_{\theta}g_{\phi}(x')))]$$

## Question 11
How to train GANs?

GAN training loop textual diagram

```
FLOWCHART DIAGRAM:

At the top:
- A diamond decision node labeled "fake ↔ real"
- Arrow points down to node D

Node D (trapezoid shape):
- Has two outputs branching downward
- Left branch: leads to x_fake (with a ghost/spirit image icon)
- Right branch: leads to x_real (with a dog/puppy image icon)

Left path (fake):
- x_fake connects to node G (trapezoid shape)
- G outputs to "z ~ p_z" (sampling from distribution p_z)

Right path (real):
- x_real connects to a cylindrical database labeled "data"
- The database contains multiple real images (appears to show vehicles, dogs, outdoor scenes)

Key elements:
- D = Discriminator
- G = Generator
- x_fake = fake generated samples
- x_real = real data samples
- z ~ p_z = latent variable sampled from prior distribution
- The diagram shows a GAN (Generative Adversarial Network) architecture where:
  * Generator G takes noise z and produces fake samples x_fake
  * Discriminator D evaluates both fake samples and real samples from the data
  * Discriminator decides whether inputs are "fake" or "real"
```


Select one or more:
a. 
$$\underset{G}{min}\underset{D}{max}J(G,D)=E_{x\sim p_{d(x)}}[log(1-D(x))]+E_{z\sim p(z)}[logD(G(z))]$$
b.
$$\underset{G}{min}\underset{D}{max}J(G,D)=E_{x\sim p_{d(x)}}[logD(x))]+E_{z\sim p(z)}[log(1-D(G(z)))]$$
c.
$$\underset{\theta, \phi}{min}E_{x\sim P}[d(\stackrel{\sim}{x},g_{\phi}(f_{\theta}(x))]$$
d.
$$\underset{G}{max}\underset{D}{min}J(G,D)=E_{x\sim p_{d(x)}}[logD(x))]+E_{z\sim p(z)}[log(1-D(G(z)))]$$

## Question 12

Consider the below seq2deq model. We apply global attention to compute the context vector. What are correct?

```
SEQUENCE DIAGRAM (Left to Right):

Top row (a_t sequence):
- a_1 (blue box, value 0.3) → a_2 (blue box, value 0.1) → a_3 (blue box, value 0.4) → a_4 (blue box, value 0.2) → c_t (dark red box) → ? (yellow box)
- Arrows connect each element sequentially from left to right

Bottom row (h̄ sequence):
- h̄_1 (blue box) → h̄_2 (blue box) → h̄_3 (blue box) → h̄_4 (blue box) → h_t (dark red box) → h_t (dark red box)
- Arrows connect each element sequentially from left to right

Vertical connections:
- Each a_i box has an upward arrow from corresponding h̄_i box below it
- The final c_t and h_t boxes are also vertically connected

Bottom labels (under h̄ boxes):
- Under h̄_1: "I"
- Under h̄_2: "am"
- Under h̄_3: "a"
- Under h̄_4: "student"
- Under first h_t: "_" (underscore/blank)
- Under second h_t: "Je"

Key elements:
- a_t = attention weights (sum to 1.0: 0.3 + 0.1 + 0.4 + 0.2)
- h̄_i = encoder hidden states for input sequence "I am a student"
- c_t = context vector (weighted sum of encoder states)
- h_t = decoder hidden states
- ? = predicted output token
- This represents an attention mechanism in sequence-to-sequence translation (English "I am a student" → French "Je...")
```

Select one or more:
a.
The first word is more important than other words to the generation of the current output word.
b.
$$c_t=0.1\stackrel{-}{h}_2 + 0.4\stackrel{-}{h}_3 + 0.2\stackrel{-}{h}_4$$
c.
$$c_t=0.3\stackrel{-}{h}_1 + 0.1\stackrel{-}{h}_2 + 0.4\stackrel{-}{h}_3 + 0.2\stackrel{-}{h}_4$$
d.
$$c_t=0.2\stackrel{-}{h}_1 + 0.4\stackrel{-}{h}_2 + 0.1\stackrel{-}{h}_3 + 0.3\stackrel{-}{h}_4$$
e.
The third word is more important than other words to the generation of the current output word.


# Part B - Short Workout & Knowledge Questions (8 questions, 40 marks)
**Introduction**
Part B contains 8 short workout questions, worthing 40 marks. These questions typically require short knowledge answers and calculations based on the knowledge you have learned from the unit. Having the calculator handy for these questions is recommended.
## Question 13

Consider a feed-forward neural network as shown in the figure for spam email detection with two 10 labels (spam=1 and non-spam=2). Assume that we feed a feature vector x=[-1,1]T with true label y=2 to the network.

NEURAL NETWORK DIAGRAM WITH EQUATIONS:

Network Structure (Left side):
- Input layer: 2 nodes (bottom)
- Hidden layer: 3 nodes (middle)
- Output layer: 2 nodes (top, labeled "spam" and "non-spam")
- All nodes are connected with lines showing full connectivity between layers

Mathematical Formulations (Right side):

Output layer (Layer 2):
- h², p = softmax(h²)
- W² = [1  -1]  , b² = [0]
       [0   1]         [1]
       [    1]

Hidden layer (Layer 1):
- h̃¹, h¹ = ReLU(h̃¹)
- W¹ = [ 1   0]  , b¹ = [-2]
       [ 0   1]         [ 0]
       [-1   0]         [ 1]

Input layer:
- x = [-1, 1]ᵀ = [-1]  , y = 2
                 [ 1]

Key notation:
- W^i = weight matrix for layer i
- b^i = bias vector for layer i
- h̃^i = pre-activation values
- h^i = post-activation values
- x = input vector
- y = target label (class 2)
- p = output probabilities from softmax
- This represents a binary classification network (spam vs non-spam) with one hidden layer

13a.
What are the formulas and the values of $\stackrel{-}{h^1}, h^1$? Note: You can use the notion $[a,b,c]^T$ or $[[a], [b], [c]]$ to represent the corresponding column vector.

13b.
What are the formulas and the values for the logits $h^2$ and the prediction probabilities p?


13c.
What are the predicted label $\hat y$ and the cross-entropy loss for this prediction? Is it a correct or incorrect prediction?

## Question 14
Consider a 4D tensor of a CNN with shape [32, 64, 64, 10]. We apply a Conv2D with 10 filters each of which has the shape [5,5,10] and strides= [3,3] with padding = ‘valid’ to obtain another tensor. On top of this tensor, we apply MaxPool2D with strides= (3,3), pool/kernel size = (2,2), and padding= ‘same’ to gain a 4D tensor. Finally, we flatten the last tensor to obtain a dense layer. What is the number of neurons on the dense layer? Show the steps of your answer.

## Question 15
Assume that we have the following text corpus, vocabulary, and embedding matrix. We input to an RNN a mini-batch of two sentences as shown in the figure.

```text
TEXTUAL DIAGRAM (faithful to the image)

┌──────────────────────────────┐
│ A) Movie review dataset       │
│ (label: pos=1, neg=0)         │
│ 1. "I really like this movie"          → pos(1) │
│ 2. "This is a bad movie to watch"      → neg(0) │
│ 3. "I really love this movie"          → pos(1) │
│ 4. "I do not recommend you to watch this movie" → neg(0) │
│ 5. "This movie is fantastic"           → pos(1) │
└───────────────┬──────────────┘
                │ build vocabulary (+ OOV buckets)
                v
┌──────────────────────────────────────────────────────────┐
│ B) Vocabulary → integer indices                           │
│ In-vocabulary tokens:                                     │
│   1: like                                                  │
│   2: love                                                  │
│   3: bad                                                   │
│   4: fantastic                                             │
│   5: not                                                   │
│   6: recommend                                             │
│                                                          │
│ Not in vocabulary → grouped into OOV “buckets” (2 buckets) │
│   7: { I, movie, this, watch }                             │
│   8: { This, is, to, really, pad }                         │
└───────────────┬──────────────────────────────────────────┘
                │ embedding lookup by index
                v
┌──────────────────────────────────────────────┐
│ C) Embedding matrix U  (shape: 8 × 2)         │
│ (embedding size = 2, so each token → 2 numbers)│
│ Row i is U_i = embedding vector for index i   │
│                                                │
│ U_1 = [-1,   2  ]   U_5 = [ 1,  -2.5]          │
│ U_2 = [ 1,  -1  ]   U_6 = [-1.5, -0.5]         │
│ U_3 = [-1,  -2  ]   U_7 = [-4,   2  ]          │
│ U_4 = [-1,   3.5]   U_8 = [ 1,  -3  ]          │
└───────────────┬──────────────────────────────┘
                │ convert token sequences → embedding sequences
                v
┌──────────────────────────────────────────────────────────────────────┐
│ D) Example mini-batch shown (B=2 sequences), padded to length T=5     │
│ Each column is a time step t; each cell shows [seq1_token | seq2_token]│
│                                                                      │
│ t=1: [ This      | I        ]                                       │
│ t=2: [ movie     | really   ]                                       │
│ t=3: [ is        | love     ]                                       │
│ t=4: [ fantastic | this     ]                                       │
│ t=5: [ <pad>     | movie    ]                                       │
│                                                                      │
│ For each token w at time t:  x_t = U[index(w)]   where x_t ∈ R^2     │
│ (For the batch, the RNN receives 2 embedding vectors per time step.) │
└───────────────┬──────────────────────────────────────────────────────┘
                │ feed embeddings through an unrolled RNN
                v
┌──────────────────────────────────────────────────────────────────────┐
│ E) RNN sentiment classifier (unrolled through time)                   │
│                                                                      │
│  x1 → [RNN cell] → h1 → [RNN cell] → h2 → ... → h5 → [sigmoid] → ŷ   │
│        (t=1)          (t=2)                    (t=5)                 │
│                                                                      │
│ Output decision rule shown:                                           │
│   if ŷ ≥ 0.5  → POSITIVE (pos)                                        │
│   if ŷ < 0.5  → NEGATIVE (neg)                                        │
└──────────────────────────────────────────────────────────────────────┘
```

15a.
What are the numeric input items at each timestep really fed to the RNN?

15b.
What is the numeric value of the 3D tensor with the shape [batch_size, seq_len, embed_size] which is the output of the embedding layer? Note: you can use NumPy format to represent a 3D array.

## Question 16
Read the following code and provide the shapes of the tensors x, h1, h2, h3, h4, h5, h6.
```python
embed_size = 64
vocab_size = 200
x = tf.keras.Input(shape=[5], dtype='int64')
h1 = tf.keras.layers.Embedding(vocab_size, embed_size)(x)
h2 = tf.keras.layers.GRU(8, return_sequences=True)(h1)
h3 = tf.keras.layers.GRU(8, return_sequences=True)(h2)
h4 = tf.keras.layers.GRU(16, return_sequences=True)(h3)
h5 = tf.keras.layers.Flatten()(h4)
h6 = tf.keras.layers.Dense(100, activation='softmax')(h5)
```
Note: the shapes should contain one dimension with the value None for batch size

## Question 17

```python
x = Input((32,32,3))
h1 = Conv2D(filters=10, kernel_size=(3,3), strides=(1,1), padding='SAME')(x)
h2 = MaxPool2D(pool_size=(2,2), strides=(2,2), padding='VALID')(h1)
h3 = Conv2D(filters=20, kernel_size=(3,3), strides=(1,1), padding='VALID')(h2)
h4 = MaxPool2D(pool_size=(2,2), strides=(2,2), padding='SAME')(h3)
h5 = Flatten()(h4)
p = Dense(units=10, activation='softmax')(h5)
```
Note: the shapes must contain one dimension with the value None for batch size.

## Question 18
Assume that we have [6,6,1] input tensor as shown below and applying max pooling or average pooling with kernel size = [2,2], strides = [2,2], padding= valid.

MATRIX/GRID (6 rows × 6 columns):

A 6×6 matrix with integer values, shown row by row from top to bottom:

Row 1: [-3,  1,  4,  2, -3,  1]
Row 2: [-2,  1, -2, -3,  3,  2]
Row 3: [-2,  2, -5,  2, -1,  0]
Row 4: [-3,  3,  6, -4,  1, -2]
Row 5: [ 2, -3,  0,  1,  2, -1]
Row 6: [-1,  1, -1,  1, -1,  1]

Alternative representation as a 2D array:
[
  [-3,  1,  4,  2, -3,  1],
  [-2,  1, -2, -3,  3,  2],
  [-2,  2, -5,  2, -1,  0],
  [-3,  3,  6, -4,  1, -2],
  [ 2, -3,  0,  1,  2, -1],
  [-1,  1, -1,  1, -1,  1]
]

Visual structure:
- Grid cells are shown with blue/purple background
- Each cell contains a single integer value
- Values range from -5 to 6
- Grid is indexed as (row, column) starting from (0,0) at top-left

18a.
What is the output tensor if we apply max pooling? Note: you can answer the output tensor by listing its rows (row1=[], row2=[], and so on)

18b.
What is the output tensor if we apply average pooling?

## Information for Questions 19, 20

Attention mechanism allows the decoding network to look back to the input sequence and is one of the most important techniques that has helped to achieve recent breakthroughs in NLP and seq2seq models. Consider the following encoding sequence diagram of length 3 from the source and we are interested in using a global attention mechanism to decode the first target output. 

ATTENTION MECHANISM DIAGRAM (Encoder-Decoder with Alignment):

Structure from bottom to top and left to right:

ENCODER (Source) - Bottom row:
┌─────────────────────────────────────────────┐
│ Sequence of encoder hidden states:          │
│ h̄₁ → h̄₂ → h̄₃ → ... (continues right)       │
│ (blue boxes connected by arrows)            │
│ Each box has upward arrow (recurrent input) │
└─────────────────────────────────────────────┘
Label: "source"

DECODER - Right side:
┌──────────────────────────────────┐
│ Two decoder hidden states shown: │
│ h_t and h_{t-1} (purple boxes)   │
│ Connected left to right          │
│ Each has upward arrow input      │
└──────────────────────────────────┘

ATTENTION MECHANISM - Center/Top:
┌────────────────────────────────────────────────────┐
│ a_t (blue box, labeled "alignment weights")        │
│ - Receives input from decoder state h_t            │
│ - Has connections FROM all encoder states:         │
│   * h̄₁ → a_t (diagonal line upward-left)          │
│   * h̄₂ → a_t (diagonal line upward-left)          │
│   * h̄₃ → a_t (diagonal line upward-left)          │
│   * ... (multiple encoder states connect to a_t)   │
└────────────────────────────────────────────────────┘

CONTEXT VECTOR - Top:
┌──────────────────────────────────────────────┐
│ c_t (orange box, labeled "context")          │
│ - Receives input from a_t (arrow upward)     │
│ - Represents weighted sum of encoder states  │
└──────────────────────────────────────────────┘

Key Connections:
1. Encoder states (h̄₁, h̄₂, h̄₃, ...) process source sequence left-to-right
2. All encoder states connect to alignment weights a_t
3. Decoder state h_t influences alignment computation a_t
4. Alignment weights a_t compute context vector c_t
5. Context vector c_t is used by decoder (connection to h_t implied)

Mathematical interpretation:
- a_t = alignment/attention weights at time step t
- c_t = Σᵢ aₜᵢ · h̄ᵢ (weighted sum of encoder hidden states)
- The attention mechanism allows decoder to focus on relevant source positions

### Question 19
Assume that the encoder and decoder hidden states have the same dimension and we use the dot product to compute the alignment scores between them. Write down the analytical expressions to
compute the alignment scores and alignment weights at(s) for s=1,2,3.

### Question 20
For simplicity, assuming the encoder hidden states are scalars with the following values $\stackrel{-}{h_1}=1, \stackrel{-}{h_2}=-1, \stackrel{-}{h_3}=2$, calculate the alignment weight vector at and then the context vector $c_t$ with the decoder hidden state $h_t=1$. Note that we assume using the sign score function $score(h_t, \stackrel{-}{h_s})=sign(h_t, \stackrel{-}{h_s})$ where sign(x) returns 1 if x≥0 and -1 if otherwise. 

# Part C: Mixed & Written-Answer Questions (10 questions, 35 marks)

(This section assesses one's knowledge and understanding of the lectures)

## Question 21
The following questions access your understanding of Word2Vec models. In your answer, to demonstrate your ideas, you can use the example sentence: "deep learning is really powerful". However, you can freely make your own example sentence.

21a.
What is the purpose of Word2Vec models?

21b.
Describe the pretext task of Skip-gram in training a Word2Vec model. What are the drawbacks of Skip-gram?

21c.
Describe Skip-gram with negative sampling

## Question 22
Considering training a deep learning model with the following plot. Describe the tendencies of the training loss, valid loss, and training accuracy, valid accuracy. Does the overfitting phenomenon happen? Explain your answer. When (i.e., at which epoch) should we do early stopping this training process?

TRAINING METRICS PLOT (Accuracy & Loss vs Epochs):

Plot structure:
- X-axis: Epochs (0.0 to 20.0)
- Y-axis (left): Accuracy (0.3 to 0.9)
- Y-axis (right): Loss (0.75 to 2.50)
- 4 lines plotted with different colors and markers

LINE 1 - Train Accuracy (green with circle markers):
Epochs:  0.0  2.5  5.0  7.5  10.0  12.5  15.0  17.5  20.0
Values:  0.45 0.53 0.60 0.68  0.75  0.80  0.84  0.87  0.90
Trend: Steady increase throughout training (learning curve)

LINE 2 - Valid Accuracy (blue with circle markers):
Epochs:  0.0  2.5  5.0  7.5  10.0  12.5  15.0  17.5  20.0
Values:  0.42 0.48 0.55 0.58  0.60  0.60  0.61  0.62  0.63
Trend: Increases initially, then plateaus around epoch 10 at ~0.60-0.63

LINE 3 - Train Loss (orange with circle markers):
Epochs:  0.0  2.5  5.0  7.5  10.0  12.5  15.0  17.5  20.0
Values:  2.20 1.95 1.70 1.45  1.20  0.95  0.85  0.80  0.78
Trend: Steady decrease throughout training

LINE 4 - Valid Loss (red with circle markers):
Epochs:  0.0  2.5  5.0  7.5  10.0  12.5  15.0  17.5  20.0
Values:  2.25 2.15 1.85 1.75  1.45  1.35  1.30  1.35  1.38
Trend: Decreases initially, reaches minimum around epoch 12.5, then increases slightly

## Information for Questions 23, 24, and 25
John is a research scientist who is doing a research project with a small-size image dataset. To enrich this dataset, John decides to use Generative Adversarial Network (GAN) to automatically produce novel high-quality fake images from noises $z\sim P z = N(0,I)$. Assume that for his GAN, John uses a
discriminator D and a generator G.

### Question 23
Describe the roles of D and G in the min-max game of GAN

### Question 24
What are the optimization problems to train D and G?

### Question 25
With an appropriate setting, John can train to reach the optimal D* and G* for which John observes that D* (x)=0.5 for real and fake images x. Explain why it happens.

## Question 26
One potential problem with using CNNs is that they cannot realize the relative spatial relationship among objects in an image. Let us consider two images as below. Because CNNs have the power to learn the objects of eyes, nose, and mouth, but not spatial relationships among them, they could incorrectly classify the right image as a human face. Discuss why this is the case for CNNs.

### Question 27
What is underfitting? In the context of deep learning, give an example of a scenario when underfitting can happen?

## Question 28
What is overfitting in machine learning?
## Question 29
In the context of deep learning, give an example of a scenario when overfitting can happen?
## Question 30
List TWO solutions to combat overfitting problems in deep learning and briefly explain why they can help to combat overfitting.